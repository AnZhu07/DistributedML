{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "#import matplotlib.pyplot as plt\n",
    "\n",
    "# Function to split the dataset into n subsets\n",
    "def split_dataset(dataset, n, sub_length):\n",
    "    total_length = len(dataset)\n",
    "    subset_length = total_length // sub_length\n",
    "    subsets = []\n",
    "    for i in range(n):\n",
    "        subset = torch.utils.data.Subset(dataset, range(i * subset_length, (i + 1) * subset_length))\n",
    "        subsets.append(subset)\n",
    "    return subsets\n",
    "\n",
    "# Preparing the Dataset\n",
    "batch_size_train = 10 \n",
    "batch_size_test = 1000\n",
    "learning_rate = 0.05 \n",
    "momentum = 0.5\n",
    "log_interval = 10\n",
    "random_seed = 1\n",
    "nr_agents = 10\n",
    "torch.backends.cudnn.enabled = False\n",
    "torch.manual_seed(random_seed)\n",
    "\n",
    "#training dataset\n",
    "full_dataset = torchvision.datasets.MNIST('/files/', train=True, download=True,\n",
    "                                          transform=torchvision.transforms.Compose([\n",
    "                                              torchvision.transforms.ToTensor(),\n",
    "                                              torchvision.transforms.Normalize(\n",
    "                                                  (0.1307,), (0.3081,))\n",
    "                                          ]))\n",
    "#testing dataset\n",
    "test_dataset = torchvision.datasets.MNIST('/files/', train=False, download=True,\n",
    "                             transform=torchvision.transforms.Compose([\n",
    "                               torchvision.transforms.ToTensor(),\n",
    "                               torchvision.transforms.Normalize(\n",
    "                                 (0.1307,), (0.3081,))\n",
    "                             ]))\n",
    "\n",
    "# Splitting the dataset into n subsets for n agents\n",
    "n_subsets = nr_agents  \n",
    "sub_len = 10  #change this if want to modify the size of each agent's dataset\n",
    "subset_datasets = split_dataset(full_dataset, n_subsets, sub_len)\n",
    "\n",
    "# creating train loaders list and test loaders list\n",
    "train_loaders = []\n",
    "test_loaders = []\n",
    "\n",
    "for subset_dataset in subset_datasets:\n",
    "    train_loader = torch.utils.data.DataLoader(subset_dataset, batch_size=batch_size_train, shuffle=True)\n",
    "    test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size_test, shuffle=True)\n",
    "    train_loaders.append(train_loader)\n",
    "    test_loaders.append(test_loader)\n",
    "\n",
    "\n",
    "examples = enumerate(test_loaders[1])\n",
    "batch_idx, (example_data, example_targets) = next(examples)\n",
    "example_data.shape\n",
    "\n",
    "print(len(train_loaders[0].dataset))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "fig = plt.figure()\n",
    "for i in range(6):\n",
    "  plt.subplot(2,3,i+1)\n",
    "  plt.tight_layout()\n",
    "  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n",
    "  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n",
    "  plt.xticks([])\n",
    "  plt.yticks([])\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Buidling the network\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "#torch.nn layers as which contain trainable parameters\n",
    "#torch.nn.functional are purely functional\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n",
    "        self.conv2_drop = nn.Dropout2d()\n",
    "        self.fc1 = nn.Linear(320, 50)\n",
    "        self.fc2 = nn.Linear(50, 10)\n",
    "\n",
    "    #defines the way we compute our output using the given layers and functions\n",
    "    def forward(self, x):\n",
    "        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n",
    "        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n",
    "        x = x.view(-1, 320)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.dropout(x, training=self.training)\n",
    "        x = self.fc2(x)\n",
    "        return F.log_softmax(x)\n",
    "    \n",
    "# initialize the networks and the optimizers\n",
    "# store in a list\n",
    "networks = [Net() for agent in range(nr_agents)]\n",
    "optimizers = [optim.SGD(networks[agent].parameters(), lr=learning_rate, momentum=momentum) for agent in range(nr_agents)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#define test function to inspect accuracy\n",
    "accuracy=[]\n",
    "\n",
    "def test(agent): \n",
    "  networks[agent].eval()\n",
    "  test_loss = 0\n",
    "  correct = 0\n",
    "  with torch.no_grad():\n",
    "    for data, target in test_loaders[agent]:\n",
    "      output = networks[agent](data)\n",
    "      test_loss += F.nll_loss(output, target, size_average=False).item()\n",
    "      pred = output.data.max(1, keepdim=True)[1]\n",
    "      correct += pred.eq(target.data.view_as(pred)).sum()\n",
    "  test_loss /= len(test_loaders[agent].dataset)\n",
    "  \n",
    "  print('\\nTest set{}: Avg. loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "    agent, test_loss, correct, len(test_loaders[agent].dataset), 100. * correct / len(test_loaders[agent].dataset)))\n",
    "  accuracy.append( 100. * correct / len(test_loaders[agent].dataset))\n",
    "\n",
    "#inital testing without training\n",
    "for agent in range(nr_agents):\n",
    "  test(agent)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define connection graph in adjacency matrix format\n",
    "#can either be hard coded or generated using Erdos Renyi's graph\n",
    "#each row represent each agent's connection to other agents in the network\n",
    "#e.g if agent 0 connnected to agent 3: graph[0][3] = 1\n",
    "\n",
    "import networkx as nx\n",
    "connect_prob = 0.2\n",
    "random_graph =nx.erdos_renyi_graph(nr_agents, connect_prob)\n",
    "graph = nx.to_numpy_array(random_graph)\n",
    "\n",
    "#each agent is connected to itself, so need to change all diagonal element to be 1\n",
    "for i in range(len(graph)):\n",
    "    graph[i][i]=1\n",
    "print(graph)\n",
    "nx.draw(random_graph, with_labels = True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from final_pack import decentralised\n",
    "import copy\n",
    "#define epochs and average interval\n",
    "ep = 15\n",
    "avg_interval = 10\n",
    "\n",
    "new_network = decentralised(train_loaders, networks, optimizers, graph)\n",
    "\n",
    "for epoch in range(1, ep):\n",
    "\n",
    "    print('epoch',epoch)\n",
    "    \n",
    "    while new_network.train_finish != True:\n",
    "        new_network.avg_n()\n",
    "        new_network.step_train(avg_interval)\n",
    "        print('average break')\n",
    "\n",
    "    networks = copy.deepcopy(new_network.model) #load back modified networks\n",
    "\n",
    "    for agent in range(nr_agents):\n",
    "        test(agent)\n",
    "\n",
    "    new_network.train_finish = False #initialise for next epoch\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualise accuracy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# Some example data to display\n",
    "x = [i for i in range(ep)]\n",
    "y = [[1]*ep for i in range(nr_agents)] \n",
    "\n",
    "for e in range(ep):\n",
    "    for i in range (nr_agents):\n",
    "        y[i][e]=accuracy[e*nr_agents+i]\n",
    "\n",
    "plt.title('accuracy for each agent')\n",
    "plt.xlabel('epoch')\n",
    "plt.ylabel('accuracy')\n",
    "plt.yticks(np.arange(0, 105, 5.0))\n",
    "plt.plot(x, y[0], marker='o', linestyle='-', color='red')\n",
    "plt.plot(x, y[1], marker='o', linestyle='-', color='blue')\n",
    "plt.plot(x, y[2], marker='o', linestyle='-', color='pink')\n",
    "plt.plot(x, y[3], marker='o', linestyle='-', color='green')\n",
    "plt.plot(x, y[4], marker='o', linestyle='-', color='orange')\n",
    "plt.plot(x, y[5], marker='o', linestyle='-', color='black')\n",
    "plt.plot(x, y[6], marker='o', linestyle='-', color='yellow')\n",
    "plt.plot(x, y[7], marker='o', linestyle='-', color='purple')\n",
    "plt.plot(x, y[8], marker='o', linestyle='-', color='brown')\n",
    "plt.plot(x, y[9], marker='o', linestyle='-', color='gray')\n",
    "\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
